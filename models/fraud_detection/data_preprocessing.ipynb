{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplyChain = pd.read_csv(\"../../data/raw/Q1_2015.csv\", encoding='ISO-8859-1')\n",
    "# future_data = pd.read_csv(\"../../data/raw/future_data.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplyChain['order date']= pd.to_datetime(supplyChain['order date (DateOrders)'])\n",
    "supplyChain['shipping date']= pd.to_datetime(supplyChain['shipping date (DateOrders)'])\n",
    "supplyChain['order year']=supplyChain['order date'].dt.year\n",
    "supplyChain['order month']=supplyChain['order date'].dt.month\n",
    "supplyChain['order day']=supplyChain['order date'].dt.day\n",
    "supplyChain['order hour']=supplyChain['order date'].dt.hour\n",
    "supplyChain['order minute']=supplyChain['order date'].dt.minute\n",
    "\n",
    "supplyChain['shipping year']=supplyChain['shipping date'].dt.year\n",
    "supplyChain['shipping month']=supplyChain['shipping date'].dt.month\n",
    "supplyChain['shipping day']=supplyChain['shipping date'].dt.day\n",
    "supplyChain['shipping hour']=supplyChain['shipping date'].dt.hour\n",
    "supplyChain['shipping minute']=supplyChain['shipping date'].dt.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n=supplyChain.loc[:,['Type','Days for shipment (scheduled)','order year','order month','order day','order hour','order minute','Benefit per order','Category Name','Latitude','Longitude','Customer Segment','Department Name','Market','Order City','Order Country','Order Item Discount','Order Item Product Price','Order Item Quantity','Order Item Total','Order State','Product Name','shipping year','shipping month','shipping day','shipping hour','shipping minute','Shipping Mode','Late_delivery_risk','Order Status']]\n",
    "# data_n.info()\n",
    "\n",
    "data_n['Order Status']= [0 if i!='SUSPECTED_FRAUD' else 1 for i in data_n['Order Status']]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc=LabelEncoder()\n",
    "for i in data_n.columns:\n",
    "    if data_n[i].dtype=='object':\n",
    "        data_n[i]=enc.fit_transform(data_n[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y=data_n['Order Status']\n",
    "X=data_n.drop(['Order Status'],axis=1)\n",
    "name = X.columns\n",
    "X=StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=name)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score after RFE: 0.9961\n",
      "Feature ranking: [ 1  4 15 10  1  1  1  1  7  1  1  9 11 14  1  1  3  6 12  2  1  8 13  5\n",
      "  1  1  1  1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanhuanhuang/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "mlflow.set_experiment('Feature_Selection_with_RFE')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfe = RFE(estimator=rf_classifier, n_features_to_select=15, step=1)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform the data\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    \n",
    "    # Train a new classifier on the transformed data\n",
    "    rf_classifier.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = rf_classifier.score(X_test_rfe, y_test)\n",
    "    print(f\"Model score after RFE: {score:.4f}\")\n",
    "    \n",
    "    # Log parameters, metrics, and model\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"n_features_to_select\", 15)\n",
    "    mlflow.log_metric(\"accuracy\", score)\n",
    "    mlflow.sklearn.log_model(rf_classifier, \"model\")\n",
    "    \n",
    "    # Get and log the ranking of the features\n",
    "    ranking = rfe.ranking_\n",
    "    print(f\"Feature ranking: {ranking}\")\n",
    "    mlflow.log_param(\"feature_ranking\", ranking.tolist())\n",
    "\n",
    "# To view the experiments, run the MLflow UI in terminal:\n",
    "# mlflow ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = name[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'order day', 'order hour', 'order minute', 'Benefit per order',\n",
       "       'Latitude', 'Longitude', 'Order City', 'Order Country', 'Order State',\n",
       "       'shipping day', 'shipping hour', 'shipping minute', 'Shipping Mode',\n",
       "       'Late_delivery_risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_sel = X_resampled[selected_features.tolist()]\n",
    "X_test_sel =  X_test[selected_features.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resampled = pd.merge(X_resampled_sel, y_resampled, left_index=True, right_index=True)\n",
    "# train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sel = pd.merge(X_test_sel, y_test, left_index=True, right_index=True)\n",
    "# test_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_2015Q1 = pd.concat([train_resampled, test_sel], axis=0)\n",
    "resampled_2015Q1['Order Status'] = resampled_2015Q1['Order Status'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order Status\n",
       "0    14878\n",
       "1    11257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resampled_2015Q1['Order Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = Path() / \"../../data/processed\"\n",
    "DATA_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def save_csv(data, filename, data_path=DATA_PATH, encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    data.to_csv(csv_path, index=False, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "\n",
    "\n",
    "class DateConverter(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['order date'] = pd.to_datetime(X['order date (DateOrders)'])\n",
    "        X['shipping date'] = pd.to_datetime(X['shipping date (DateOrders)'])\n",
    "        return X\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for feature in ['order date', 'shipping date']:\n",
    "            prefix = feature.split()[0]\n",
    "            X[f'{prefix} year'] = X[feature].dt.year\n",
    "            X[f'{prefix} month'] = X[feature].dt.month\n",
    "            X[f'{prefix} day'] = X[feature].dt.day\n",
    "            X[f'{prefix} hour'] = X[feature].dt.hour\n",
    "            X[f'{prefix} minute'] = X[feature].dt.minute\n",
    "        X_n = X.loc[:,['Type','Days for shipment (scheduled)','order year','order month','order day','order hour',\n",
    "                        'order minute','Benefit per order','Category Name','Latitude','Longitude','Customer Segment',\n",
    "                        'Department Name','Market','Order City','Order Country','Order Item Discount','Order Item Product Price',\n",
    "                        'Order Item Quantity','Order Item Total','Order State','Product Name','shipping year','shipping month',\n",
    "                        'shipping day','shipping hour','shipping minute','Shipping Mode','Late_delivery_risk','Order Status']]\n",
    "        return X_n\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'object':\n",
    "                le = LabelEncoder()\n",
    "                le.fit(X[col])\n",
    "                self.encoders[col] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, encoder in self.encoders.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = encoder.transform(X[col])\n",
    "        return X\n",
    "    \n",
    "class DataFrameConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_names):\n",
    "        self.column_names = column_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X, columns=self.column_names)\n",
    "\n",
    "def build_pipeline():\n",
    "    date_cols = ['order date (DateOrders)', 'shipping date (DateOrders)']\n",
    "    \n",
    "    all_cols = ['Type','Days for shipment (scheduled)','order year','order month','order day','order hour',\n",
    "                        'order minute','Benefit per order','Category Name','Latitude','Longitude','Customer Segment',\n",
    "                        'Department Name','Market','Order City','Order Country','Order Item Discount','Order Item Product Price',\n",
    "                        'Order Item Quantity','Order Item Total','Order State','Product Name','shipping year','shipping month',\n",
    "                        'shipping day','shipping hour','shipping minute','Shipping Mode','Late_delivery_risk','Order Status']\n",
    "\n",
    "\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('date_converter', DateConverter()),\n",
    "        ('feature_engineering', FeatureEngineering()),\n",
    "        ('encode_categorical', CategoricalEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('to_dataframe', DataFrameConverter(column_names=all_cols))  \n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def apply_smote(X_train, y_train):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def select_and_concatenate_datasets(X_resampled, y_resampled, X_test, y_test):\n",
    "    selected_features = ['Type', 'order day', 'order hour', 'order minute', 'Benefit per order', 'Latitude', 'Longitude', 'Order City', 'Order Country', 'Order State', 'shipping day', 'shipping hour', 'shipping minute', 'Shipping Mode', 'Late_delivery_risk']\n",
    "    X_resampled_sel = X_resampled[selected_features]\n",
    "    X_test_sel = X_test[selected_features]\n",
    "    train_resampled = pd.concat([X_resampled_sel, y_resampled], axis=1)\n",
    "    test_sel = pd.concat([X_test_sel, y_test], axis=1)\n",
    "    concatenated_datasets = pd.concat([train_resampled, test_sel])\n",
    "    return concatenated_datasets\n",
    "\n",
    "def process_data_from_csv(filepath):\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(filepath, encoding='ISO-8859-1')\n",
    "    \n",
    "    # Build and apply the preprocessing pipeline\n",
    "    pipeline = build_pipeline()\n",
    "    df_processed = pipeline.fit_transform(df)\n",
    "    \n",
    "    # Prepare target and features\n",
    "    y = df['Order Status'].map(lambda x: 0 if x != 'SUSPECTED_FRAUD' else 1)\n",
    "    X = df_processed.drop('Order Status', axis=1)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_resampled, y_resampled = apply_smote(X_train, y_train)\n",
    "    \n",
    "    # Concatenate datasets for the final dataset\n",
    "    final_dataset = select_and_concatenate_datasets(X_resampled, y_resampled, X_test, y_test)\n",
    "    \n",
    "    return final_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(process_data_from_csv(\"../../data/raw/Q1_2015.csv\"), 'Q1_2015_fraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order Status\n",
       "0    14878\n",
       "1    11257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_dataset['Order Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(process_data_from_csv(\"../../data/raw/future_data.csv\"), 'future_data_fraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
